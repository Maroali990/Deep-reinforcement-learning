{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E1jsBF16L8Zu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##         state 1 is equal to state 2 for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yRMb-GF7-L_V"
   },
   "outputs": [],
   "source": [
    "# Create Gridworld object\n",
    "\n",
    "class Gridworld:\n",
    "    \n",
    "    def __init__(self,dim):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.gid_world = []\n",
    "        self.reward_world = []\n",
    "        \n",
    "        self.gid_world_original = []\n",
    "        self.reward_world_original = []\n",
    "        \n",
    "        self.free_fields = []\n",
    "        self.goal = []\n",
    "        self.tele_idx = []\n",
    "        \n",
    "        self.finished = False\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        ######### Build GW #########\n",
    "\n",
    "        for x in range(self.dim+1):\n",
    "            self.grid_world = [\"O\"] * (x * x)\n",
    "\n",
    "        # Create obstacles\n",
    "\n",
    "        self.grid_world = np.array(self.grid_world)\n",
    "\n",
    "        num_obs = int((self.dim*self.dim)/8) # specify number of obstacles\n",
    "\n",
    "        obstacle_indices = np.random.choice(np.arange(1,self.grid_world.size), replace=False, size=num_obs) # start at one to not place obstacles at player pos\n",
    "\n",
    "        self.grid_world[obstacle_indices] = \"X\"\n",
    "        \n",
    "        ######### Build RW and Teleport #########\n",
    "\n",
    "        # Assign rewards to states\n",
    "\n",
    "        self.reward_world =copy.deepcopy(self.grid_world.flatten()) # create seperate array for reward\n",
    "\n",
    "        self.free_fields = [x for x in np.arange(self.reward_world.size) if x not in obstacle_indices if x != 0] # generate list of free fields\n",
    "\n",
    "        np.random.shuffle(self.free_fields) # shuffle free fields\n",
    "\n",
    "        self.goal = self.free_fields[-1] # choose index for postive reward (terminal state)\n",
    "        \n",
    "        self.tele_idx = [self.free_fields[-2],self.free_fields[-3]]# choose 2 indices for teleports\n",
    "        \n",
    "        rew_neg_amount = 5 # specify number of negative rewards\n",
    "\n",
    "        rew_neg_indices = np.random.choice(self.free_fields[1:-3], replace=False, size=rew_neg_amount) # randomly choose incides for negative rewards\n",
    "\n",
    "        self.reward_world[rew_neg_indices] = \"-\" # place negative rewards\n",
    "\n",
    "        self.reward_world[self.goal] = \"+\" # place positive reward (terminal state)\n",
    "        \n",
    "        self.reward_world[self.tele_idx] = \"ยง\" # place teleports\n",
    "        \n",
    "        \n",
    "        # Set starting point #\n",
    "\n",
    "        self.grid_world[0] = \"P\" # top left\n",
    "        \n",
    "\n",
    "        # Save Backup\n",
    "\n",
    "        self.reward_world_original = copy.deepcopy(self.reward_world) \n",
    "        \n",
    "        self.grid_world_original = copy.deepcopy(self.grid_world)\n",
    "        \n",
    "        \n",
    "        return self.grid_world, self.reward_world\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.reward_world = copy.deepcopy(self.reward_world_original)\n",
    "        self.grid_world = copy.deepcopy(self.grid_world_original)\n",
    "\n",
    "        return self.grid_world, self.reward_world\n",
    "\n",
    "    def move(self, action):\n",
    "        \n",
    "        idx = np.where(self.grid_world == \"P\")[0]\n",
    "        idx = idx[0]\n",
    "        \n",
    "        self.reward = -0.3 # maybe include immediate penalty of -0.3 for all moves that dont land on a reward field\n",
    "        \n",
    "        if action == \"left\":\n",
    "            \n",
    "            # if path is Oob\n",
    "            \n",
    "            if idx == 0 or (idx%self.dim) == 0:\n",
    "        \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx-1]  == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx-1 == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx-1 == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                   \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx-1] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx-1] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx-1] = \"P\"\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"right\":\n",
    "            \n",
    "            # if path is Oob\n",
    "            \n",
    "            if idx == (self.dim-1) or idx == (len(self.grid_world)-1):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx+1] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx+1 == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx+1 == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx+1] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx+1] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx+1] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"up\":\n",
    "            \n",
    "             # if path is Oob\n",
    "            \n",
    "            if idx in range(0,(self.dim-1)):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx-self.dim] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx-self.dim == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx-self.dim == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx-self.dim] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx-self.dim] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx-self.dim] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"down\":\n",
    "            \n",
    "             # if path is Oob\n",
    "            \n",
    "            if idx in range(len(self.grid_world)-self.dim,len(self.grid_world)):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx+self.dim] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx+self.dim == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx+self.dim == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx+self.dim] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx+self.dim] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx+self.dim] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        else:\n",
    "            print(\"Please choose an action [left,right,up,down]!\")        \n",
    "    \n",
    "    def visualize(self):\n",
    "        \n",
    "        # Show GW\n",
    "        \n",
    "        print(\"Gridworld:\\n\")\n",
    "        print(self.grid_world.reshape(((self.dim, self.dim))))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Show RW\n",
    "\n",
    "        print(\"Rewardworld:\\n\")\n",
    "        print(self.reward_world.reshape(((self.dim, self.dim))))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhdb6GBm-ZR0",
    "outputId": "bff39063-2885-44a9-f5d6-7502ecdbf6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your desired grid dimension (dim X dim):\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Specify dimensions\n",
    "\n",
    "while True:    \n",
    "    try:\n",
    "        dim = int(input(\"Please provide your desired grid dimension (dim X dim):\\n\"))\n",
    "        \n",
    "        if dim >= 5:\n",
    "            break\n",
    "            \n",
    "        print(\"Dimension needs to be larger than 4!\\n\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Please provide an integer value!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ic3vK2kG-fvk",
    "outputId": "c2ec3595-2d05-4a28-c070-6a83e3e70557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridworld:\n",
      "\n",
      "[['P' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'X' 'O' 'O' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'X' 'O' 'O' 'O' 'X' 'O' 'X' 'O' 'O']\n",
      " ['O' 'O' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']]\n",
      "\n",
      "\n",
      "Rewardworld:\n",
      "\n",
      "[['O' 'O' '+' 'O' 'O' 'O' 'O' 'ยง' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O' '-']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' '-' 'O']\n",
      " ['O' 'O' 'O' '-' 'O' 'O' 'X' 'O' 'O' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' '-' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'X' 'O' 'O' '-' 'X' 'O' 'X' 'O' 'O']\n",
      " ['O' 'ยง' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GW object\n",
    "\n",
    "gw = Gridworld(dim)\n",
    "\n",
    "gw.build()\n",
    "\n",
    "# Show GW\n",
    "#the state in the reward world with + is the terminal state\n",
    "\n",
    "gw.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gw.move(\"right\")\n",
    "# gw.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gw.reset()\n",
    "# gw.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57AJ24I9AdwW"
   },
   "source": [
    "n-step Sarsa, this code is taken from https://www.geeksforgeeks.org/sarsa-reinforcement-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4Bj7W5ocAdXK"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# set initial parameters\n",
    "epsilon = 0.9\n",
    "total_episodes = 2000000\n",
    "max_steps = 1000\n",
    "alpha = 0.8\n",
    "gamma = 0.9\n",
    "\n",
    "# define actionspace\n",
    "action_space=[0,1,2,3]\n",
    "dict_moves={0:\"left\",1:\"right\",2:\"up\",3:\"down\"}\n",
    "\n",
    "# list to save the SAR\n",
    "n_list=[]\n",
    " \n",
    "# initialize Q value table \n",
    "Q = np.zeros((dim*dim,len(action_space))) # dim: number of states x actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QLreRulLC0a2"
   },
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    \n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        \n",
    "        # sample random action\n",
    "        action = random.sample(action_space,1)[0] \n",
    "        return action\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # get best action (maximize Q value)\n",
    "        action = np.argmax(Q[state, :]) # requires index of the player (state)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FXv9Owq4C9hJ"
   },
   "outputs": [],
   "source": [
    "def update(state1,state2,reward,action1,action2):\n",
    "    \n",
    "#     print(\"current state (s): \",state1, \"\\n\", \"next state (s'): \",\n",
    "#           state2,\"\\n\",\"reward (r): \",reward,\"\\n\", \"current action (a): \",\n",
    "#           dict_moves[action1],\"\\n\", \"next action (a'): \",dict_moves[action2],\"\\n\")\n",
    "    \n",
    "    idx1 = np.where(state1 == \"P\")[0][0]\n",
    "    #print(\"index 1: \",idx1)\n",
    "    \n",
    "    idx2 = np.where(state2 ==\"P\")[0][0]\n",
    "    #print(\"index 2: \",idx2)\n",
    "    \n",
    "    # get estimates\n",
    "    Q_old = Q[idx1, action1]   \n",
    "    Q_new = Q[idx2, action2]\n",
    "    Q[idx1, action1] = Q_old + alpha * (reward + (gamma *  Q_new) - Q_old)\n",
    "    \n",
    "#     print(\"Q_old: \", Q_old)\n",
    "#     print(\"Q_new: \", Q_new)\n",
    "#     print((\"Reward: \", reward))\n",
    "#     print(\"Q_calc: \", (Q_old + alpha * (reward + (gamma *  Q_new) - Q_old)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U9gWLz-5B-KN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100000\n",
      "Epoch: 200000\n",
      "Epoch: 300000\n",
      "Epoch: 400000\n",
      "Epoch: 500000\n",
      "Epoch: 600000\n",
      "Epoch: 700000\n",
      "Epoch: 800000\n",
      "Epoch: 900000\n",
      "Epoch: 1000000\n",
      "Epoch: 1100000\n",
      "Epoch: 1200000\n",
      "Epoch: 1300000\n",
      "Epoch: 1400000\n",
      "Epoch: 1500000\n",
      "Epoch: 1600000\n",
      "Epoch: 1700000\n",
      "Epoch: 1800000\n",
      "Epoch: 1900000\n",
      "Learning finished!\n"
     ]
    }
   ],
   "source": [
    "# initializing the reward\n",
    "reward = 0\n",
    "\n",
    "# epoch_guide\n",
    "\n",
    "ep_ = 0\n",
    "\n",
    "# Starting the SARSA learning\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    \n",
    "    # every 100000 epochs\n",
    "    if (ep_ % 100000) == 0 and ep_ != 0:\n",
    "        print(\"Epoch: \" + str(ep_))\n",
    "        \n",
    "#         # check exploration status\n",
    "#         unique, counts = np.unique(Q, return_counts=True)\n",
    "#         tmp = dict(zip(unique, counts))\n",
    "#         if tmp[0] < ((dim*dim)/4): # if a less then a quarter of Q values is unexplored end the algorithm\n",
    "#             break\n",
    "#         else:\n",
    "#             print(\"Unexplored: \",(tmp[0]/Q.size)*100, \"%\")\n",
    "    \n",
    "    t = 0 # reset temperatur during episodes\n",
    "    stateTMP, _ = gw.reset() # reset gridworld and get initial state   \n",
    "    \n",
    "    state1 = copy.deepcopy(stateTMP) # prevent bugs \n",
    "    \n",
    "    idx_state1 = np.where(state1 == \"P\")[0][0] # state needs to be an index for the condition work \n",
    "    action1 = choose_action(idx_state1) # get current action\n",
    "\n",
    "    while t < max_steps: \n",
    "        \n",
    "        #sgw.visualize()\n",
    "         \n",
    "        # getting the next state\n",
    "        state2, done, reward = gw.move(dict_moves[action1])\n",
    "                \n",
    "        # get index of player in next state\n",
    "        idx_state2 = np.where(state2 == \"P\")[0][0]\n",
    "        \n",
    "        # choose the next action\n",
    "        action2 = choose_action(idx_state2) # state needs to be an index for the condition work\n",
    "         \n",
    "        # calculate the Q-value\n",
    "        update(state1, state2, reward, action1, action2)\n",
    "         \n",
    "        # update state and action\n",
    "        state1 = state2\n",
    "        action1 = action2\n",
    "        \n",
    "        # update temperature\n",
    "        t += 1\n",
    "         \n",
    "        #If at the end of learning process\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    ep_ += 1\n",
    "            \n",
    "print(\"Learning finished!\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yNr6j-aLADOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.59958506e+00  1.37914333e-01 -1.25259093e+00 -6.63480061e-01]\n",
      " [ 7.58191795e-02  4.46334887e-01 -2.29226929e-01  8.62214471e-01]\n",
      " [ 8.07525294e+01  9.77665246e-01  7.96337314e-01  2.00431899e-04]\n",
      " [ 5.04419576e-01  9.53322801e-01  1.24891056e-01  5.08014919e-01]\n",
      " [ 3.64235678e-01 -2.71764271e-01  4.10550070e-01  7.91429030e-01]\n",
      " [ 9.92008528e-02  1.87898190e-02  4.38640245e-01  3.56893175e-01]\n",
      " [ 1.48636980e-01 -1.57483553e-01 -4.22066045e-02  8.85181303e-01]\n",
      " [-9.98292181e-01 -8.54926278e-01 -7.98821757e-01 -1.15096865e+00]\n",
      " [-4.33002370e-01  1.05210333e-01  1.38091850e-01  5.25312487e-01]\n",
      " [ 9.48190634e-01  2.24885802e-01  5.06824510e-01  7.00092381e-01]\n",
      " [-2.61030578e-01  8.75077517e-02 -3.89179523e-01 -8.79940637e-01]\n",
      " [ 3.55531852e-02 -4.74685371e-01 -5.12138248e-01 -3.17412460e-01]\n",
      " [-4.98170859e-03  2.11079207e-02 -1.45201279e-01  7.77692147e-01]\n",
      " [-6.93616820e-01 -6.69919182e-01 -5.22583257e-01 -1.20840119e-01]\n",
      " [-8.11740995e-01 -6.03894530e-01 -6.80929512e-01 -9.46140315e-01]\n",
      " [-1.43689183e-01 -3.09165309e-01 -2.97606139e-01 -3.91937865e-01]\n",
      " [ 7.06024034e-01 -3.06026207e-01 -7.30369343e-03 -5.07959414e-01]\n",
      " [ 1.76493959e-01  7.59725776e-01  5.15047614e-01  1.76829599e-01]\n",
      " [ 6.79705497e-02  2.44060636e-01  9.03241824e-01  5.57164469e-01]\n",
      " [ 3.76781669e-01 -1.21426035e+00  3.24104044e-01 -9.11148383e-01]\n",
      " [-9.52725068e-01 -6.34407612e-01 -9.03202901e-01 -7.76010217e-01]\n",
      " [ 5.86351089e-01  4.92193165e-01  1.13534366e-01 -9.87855781e-02]\n",
      " [-1.02068098e-01  8.96366495e-04  1.82215489e-01  1.98820162e-01]\n",
      " [-7.62068517e-01 -6.06687799e-01 -3.50460244e-01 -1.12089292e+00]\n",
      " [-7.16200019e-01 -2.74803181e-01 -6.20423505e-01 -5.58520781e-01]\n",
      " [-9.87349376e-01 -1.08858687e+00 -1.16966030e+00 -4.53706107e-01]\n",
      " [-5.39828421e-02 -4.47146025e-01  6.56126991e-01 -3.08525816e-01]\n",
      " [-3.55274869e-01 -2.81542928e-01 -5.42893781e-01  6.61344696e-01]\n",
      " [ 6.63484893e-01 -1.90383576e+00 -1.06472125e+00  1.25844168e-02]\n",
      " [ 7.54388372e-01  6.13730322e-01 -1.23401632e-01  1.62561500e-01]\n",
      " [-5.49091965e-01  1.65223426e-02 -3.45661567e-01 -2.85206240e-01]\n",
      " [-3.42663648e-01  1.28814262e-01  6.79817343e-01 -5.69437958e-01]\n",
      " [-3.99734378e-02  2.21608678e-01  7.24526541e-01  2.84942035e-01]\n",
      " [-4.53969202e+00 -2.81597440e+00 -3.95491026e+00 -5.51388688e+00]\n",
      " [-4.66922552e-01 -4.80694819e-01 -7.29627138e-01 -4.08009525e-01]\n",
      " [ 3.85351750e-01 -9.31335615e-01 -7.79200644e-01 -7.09894921e-01]\n",
      " [ 2.72863230e-01  7.72995039e-01  6.77508507e-01  6.15597309e-03]\n",
      " [-3.88609716e-01  3.23973041e-01 -1.01600084e-01 -4.95330431e-03]\n",
      " [-1.86065629e-01 -1.15726646e-02  7.69345836e-01 -1.81471829e-01]\n",
      " [ 6.62415702e-01  1.23389248e-01  4.07399376e-01 -5.20337306e-02]\n",
      " [-1.25335063e+00 -1.34738414e+00 -1.21691621e+00 -1.24877202e+00]\n",
      " [ 6.94522916e-02  3.79792255e-01  6.27605995e-01  9.23421961e-02]\n",
      " [ 7.38575671e-01  1.33728343e-01  8.12449460e-01  3.14942422e-01]\n",
      " [-3.80316851e-02  4.08554341e-01 -3.24245272e-01 -3.86630862e-01]\n",
      " [-9.14822334e-01 -1.03156563e+00 -7.70710486e-01 -1.01278233e+00]\n",
      " [-8.44106119e-01 -1.06468646e+00 -1.16645199e+00 -1.13439052e+00]\n",
      " [-1.12788113e-01  1.50314764e-01  1.31047641e-01  5.01007749e-01]\n",
      " [ 7.36260773e-01 -4.42047066e-01 -9.29995125e-01  1.86287073e-01]\n",
      " [ 6.00249510e-01  2.16484271e-01  6.73612160e-01  8.45160880e-01]\n",
      " [ 2.61084350e-01  6.06311267e-02  6.36990697e-01  3.75286786e-01]\n",
      " [ 1.99928145e-01  9.83285400e-01  5.77864763e-01  1.83911520e-01]\n",
      " [-5.62896241e-01 -4.54395052e-01  1.58403047e-01  5.32671589e-01]\n",
      " [-2.57586027e-02 -6.40307441e-01  1.48330908e-01  6.13630237e-01]\n",
      " [-1.25628807e+00 -1.22149135e+00 -1.08050082e+00 -1.32019364e+00]\n",
      " [-8.34353303e-01 -2.73727854e-01 -8.74439830e-01 -6.45533468e-01]\n",
      " [-7.95571250e-01 -7.73804283e-01 -5.46951065e-01 -8.99750581e-01]\n",
      " [-1.13964102e+00 -1.42142368e+00 -1.00526176e+00 -1.31221333e+00]\n",
      " [ 1.29419000e-01 -5.24165246e-01 -3.12548637e-01 -5.82763985e-01]\n",
      " [ 4.56824121e-01  3.15734276e-02  8.38064225e-01  6.53983382e-02]\n",
      " [ 3.14204896e-01  7.17668559e-01  9.08459071e-01  9.07727175e-01]\n",
      " [-5.67001496e-01  1.17693151e-01 -2.74784671e-01 -2.42909858e-01]\n",
      " [-6.05716505e+00 -5.50163266e+00  1.82215918e-01 -6.57519760e+00]\n",
      " [-6.71499938e-01 -9.78512453e-01 -8.35195840e-01 -1.13424646e+00]\n",
      " [-9.60231718e-01 -1.10329717e+00 -1.05252707e+00 -1.11189158e+00]\n",
      " [-1.17449459e+00 -1.10418426e+00 -1.21713266e+00 -8.95134118e-01]\n",
      " [-1.20281349e+00 -2.27484165e-01  2.61100870e-01 -1.31380207e+00]\n",
      " [-1.06645417e+00 -1.25248954e+00 -1.11114948e+00 -9.77468308e-01]\n",
      " [ 6.62093312e-01 -5.10057708e-02  3.44626384e-01  2.45799598e-01]\n",
      " [ 2.56528260e-02  3.11914473e-01  8.26323934e-01  2.85809926e-01]\n",
      " [ 6.00320792e-01  8.21749995e-01  1.79969322e-01  9.32637789e-01]\n",
      " [-3.90012272e-01 -7.55738832e-01 -8.36011166e-01 -6.73171012e-01]\n",
      " [ 4.12223020e-01  8.60463848e-01  1.38848113e-02  3.05379884e-01]\n",
      " [-1.39539089e-01  1.87552656e-01  4.69773517e-01 -4.31982549e-01]\n",
      " [-6.50977699e-01 -5.94348937e-01 -1.12471729e+00 -2.18170074e-01]\n",
      " [ 3.40630837e-01 -1.44193534e+00  6.20966512e-01 -1.48172919e+00]\n",
      " [ 2.72685797e-01  6.13634448e-02  4.90883675e-01  8.40185514e-01]\n",
      " [-4.43745137e-01 -5.35329661e-01 -4.38289427e-01 -1.11975934e+00]\n",
      " [ 1.98765266e-01  5.01761285e-01  1.57131670e-01  7.58946868e-01]\n",
      " [ 4.27711419e-01  9.12452762e-01  7.40404250e-02  6.94263097e-01]\n",
      " [ 4.60260971e-01  9.25765136e-01  4.89909737e-01  9.99428431e-01]\n",
      " [-8.61631058e-01 -8.21147626e-01 -9.69886860e-01 -1.00515695e+00]\n",
      " [ 3.98017479e-01  3.51113432e-02 -4.65671485e-01  4.97304317e-01]\n",
      " [ 4.31414145e-01  2.61548972e-01  5.35449838e-01  8.39672439e-02]\n",
      " [-2.05291890e-01  9.39205314e-02  1.05364641e-01 -2.10045712e-01]\n",
      " [ 2.53894856e-01  5.19638735e-01  1.87444979e-01  5.21684666e-01]\n",
      " [ 4.83386695e-01 -2.12954520e-01  1.02056041e-01  2.87714772e-01]\n",
      " [ 4.30530856e-01  6.55257037e-01  4.92390646e-02  4.27829095e-01]\n",
      " [ 5.29672184e-01  5.62296854e-01  6.34652915e-01  9.76195222e-01]\n",
      " [ 5.77815852e-02  2.13964063e-01  2.58468579e-01  2.16546126e-01]\n",
      " [-2.65711523e-03  8.31493932e-01 -2.97253926e-01  1.98055404e-01]\n",
      " [-1.24755829e+00 -6.14450959e-01  3.38593431e-02 -9.39309799e-01]\n",
      " [-6.82197938e-02  7.16169109e-02  5.32005315e-01 -2.84229722e-01]\n",
      " [-3.32730920e-01  1.62440541e-01 -9.63928562e-02 -4.95966527e-01]\n",
      " [ 8.92703882e-01  5.57824214e-01  8.98479072e-01  5.03663220e-01]\n",
      " [-1.42325568e-01  1.04545153e-01  5.48623111e-01  1.97436606e-01]\n",
      " [ 3.11902397e-01  2.59608112e-02  6.25750750e-01  2.61445282e-01]\n",
      " [ 7.81614728e-03  3.89291828e-01  4.35075540e-01 -2.75790250e-02]\n",
      " [-1.27223105e-01  5.20526950e-01  8.89860240e-02  1.68738768e-01]\n",
      " [-8.45243744e-01 -6.44520549e-01 -8.91176014e-01 -8.84702793e-01]\n",
      " [ 2.55469808e-01  1.16431474e-01  4.74664906e-01 -3.07125521e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Print final Q value table\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridworld:\n",
      "\n",
      "[['P' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'X' 'O' 'O' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'X' 'O' 'O' 'O' 'X' 'O' 'X' 'O' 'O']\n",
      " ['O' 'O' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']]\n",
      "\n",
      "\n",
      "Rewardworld:\n",
      "\n",
      "[['O' 'O' '+' 'O' 'O' 'O' 'O' 'ยง' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O' '-']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' '-' 'O']\n",
      " ['O' 'O' 'O' '-' 'O' 'O' 'X' 'O' 'O' 'O']\n",
      " ['O' 'X' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' '-' 'O' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'X' 'O' 'O' '-' 'X' 'O' 'X' 'O' 'O']\n",
      " ['O' 'ยง' 'X' 'O' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']]\n",
      "\n",
      "\n",
      "Learned moves: \n",
      "\n",
      "[['right' 'down' 'left' 'right' 'down' 'up' 'down' 'up' 'down' 'left']\n",
      " ['right' 'left' 'down' 'down' 'right' 'left' 'left' 'right' 'up' 'left']\n",
      " ['right' 'left' 'down' 'up' 'right' 'down' 'up' 'down' 'left' 'left']\n",
      " ['right' 'up' 'up' 'right' 'down' 'left' 'right' 'right' 'up' 'left']\n",
      " ['up' 'up' 'up' 'right' 'up' 'left' 'down' 'left' 'down' 'up']\n",
      " ['right' 'down' 'down' 'up' 'right' 'up' 'up' 'left' 'up' 'up']\n",
      " ['right' 'up' 'left' 'left' 'down' 'up' 'down' 'left' 'up' 'down']\n",
      " ['left' 'right' 'up' 'down' 'up' 'down' 'up' 'down' 'right' 'down']\n",
      " ['right' 'down' 'up' 'up' 'down' 'left' 'right' 'down' 'up' 'right']\n",
      " ['up' 'up' 'right' 'up' 'up' 'up' 'up' 'right' 'right' 'up']]\n"
     ]
    }
   ],
   "source": [
    "# print learned policy for every state\n",
    "\n",
    "moves_ls = []\n",
    "dummy = np.array([0.,0.,0.,0.])\n",
    "\n",
    "for i in Q:\n",
    "    if (i==dummy).all(): # if state only has value of 0s\n",
    "        moves_ls.append(\"None\")\n",
    "        \n",
    "    else:\n",
    "        moves_ls.append(dict_moves[np.argmax(i)])\n",
    "    \n",
    "moves_ls = np.array(moves_ls)\n",
    "moves_ls = moves_ls.reshape(dim,dim)\n",
    "\n",
    "gw.reset() \n",
    "gw.visualize()\n",
    "\n",
    "print(\"Learned moves: \\n\")\n",
    "print(moves_ls)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Sarsa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
