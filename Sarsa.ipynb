{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E1jsBF16L8Zu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yRMb-GF7-L_V"
   },
   "outputs": [],
   "source": [
    "# Create Gridworld object\n",
    "\n",
    "class Gridworld:\n",
    "    \n",
    "    def __init__(self,dim):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.gid_world = []\n",
    "        self.reward_world = []\n",
    "        \n",
    "        self.gid_world_original = []\n",
    "        self.reward_world_original = []\n",
    "        \n",
    "        self.free_fields = []\n",
    "        self.goal = []\n",
    "        self.tele_idx = []\n",
    "        \n",
    "        self.finished = False\n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        ######### Build GW #########\n",
    "\n",
    "        for x in range(self.dim+1):\n",
    "            self.grid_world = [\"O\"] * (x * x)\n",
    "\n",
    "        # Create obstacles\n",
    "\n",
    "        self.grid_world = np.array(self.grid_world)\n",
    "\n",
    "        num_obs = int((self.dim*self.dim)/8) # specify number of obstacles\n",
    "\n",
    "        obstacle_indices = np.random.choice(np.arange(1,self.grid_world.size), replace=False, size=num_obs) # start at one to not place obstacles at player pos\n",
    "\n",
    "        self.grid_world[obstacle_indices] = \"X\"\n",
    "        \n",
    "        ######### Build RW and Teleport #########\n",
    "\n",
    "        # Assign rewards to states\n",
    "\n",
    "        self.reward_world =copy.deepcopy(self.grid_world.flatten()) # create seperate array for reward\n",
    "\n",
    "        self.free_fields = [x for x in np.arange(self.reward_world.size) if x not in obstacle_indices if x != 0] # generate list of free fields\n",
    "\n",
    "        np.random.shuffle(self.free_fields) # shuffle free fields\n",
    "\n",
    "        self.goal = self.free_fields[-1] # choose index for postive reward (terminal state)\n",
    "        \n",
    "        self.tele_idx = [self.free_fields[-2],self.free_fields[-3]]# choose 2 indices for teleports\n",
    "        \n",
    "        rew_neg_amount = 5 # specify number of negative rewards\n",
    "\n",
    "        rew_neg_indices = np.random.choice(self.free_fields[1:-3], replace=False, size=rew_neg_amount) # randomly choose incides for negative rewards\n",
    "\n",
    "        self.reward_world[rew_neg_indices] = \"-\" # place negative rewards\n",
    "\n",
    "        self.reward_world[self.goal] = \"+\" # place positive reward (terminal state)\n",
    "        \n",
    "        self.reward_world[self.tele_idx] = \"ยง\" # place teleports\n",
    "        \n",
    "        \n",
    "        # Set starting point #\n",
    "\n",
    "        self.grid_world[0] = \"P\" # top left\n",
    "        \n",
    "\n",
    "        # Save Backup\n",
    "\n",
    "        self.reward_world_original = copy.deepcopy(self.reward_world) \n",
    "        \n",
    "        self.grid_world_original = copy.deepcopy(self.grid_world)\n",
    "        \n",
    "        \n",
    "        return self.grid_world, self.reward_world\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.reward_world = copy.deepcopy(self.reward_world_original)\n",
    "        self.grid_world = copy.deepcopy(self.grid_world_original)\n",
    "\n",
    "        return self.grid_world, self.reward_world\n",
    "\n",
    "    def move(self, action):\n",
    "        \n",
    "        idx = np.where(self.grid_world == \"P\")[0]\n",
    "        idx = idx[0]\n",
    "        \n",
    "        self.reward = -0.3 # maybe include immediate penalty of -0.3 for all moves that dont land on a reward field\n",
    "        \n",
    "        if action == \"left\":\n",
    "            \n",
    "            # if path is Oob\n",
    "            \n",
    "            if idx == 0 or (idx%self.dim) == 0:\n",
    "        \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx-1]  == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx-1 == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx-1 == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                   \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx-1] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx-1] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx-1] = \"P\"\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"right\":\n",
    "            \n",
    "            # if path is Oob\n",
    "            \n",
    "            if idx == (self.dim-1) or idx == (len(self.grid_world)-1):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx+1] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx+1 == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx+1 == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx+1] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx+1] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx+1] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"up\":\n",
    "            \n",
    "             # if path is Oob\n",
    "            \n",
    "            if idx in range(0,(self.dim-1)):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx-self.dim] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx-self.dim == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx-self.dim == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx-self.dim] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx-self.dim] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx-self.dim] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"down\":\n",
    "            \n",
    "             # if path is Oob\n",
    "            \n",
    "            if idx in range(len(self.grid_world)-self.dim,len(self.grid_world)):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx+self.dim] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx+self.dim == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx+self.dim == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx+self.dim] == \"+\":\n",
    "                        \n",
    "                        self.reward = +100\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx+self.dim] == \"-\":\n",
    "                        \n",
    "                        self.reward = -2\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx+self.dim] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        else:\n",
    "            print(\"Please choose an action [left,right,up,down]!\")        \n",
    "    \n",
    "    def visualize(self):\n",
    "        \n",
    "        # Show GW\n",
    "        \n",
    "        print(\"Gridworld:\\n\")\n",
    "        print(self.grid_world.reshape(((self.dim, self.dim))))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Show RW\n",
    "\n",
    "        print(\"Rewardworld:\\n\")\n",
    "        print(self.reward_world.reshape(((self.dim, self.dim))))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhdb6GBm-ZR0",
    "outputId": "bff39063-2885-44a9-f5d6-7502ecdbf6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your desired grid dimension (dim X dim):\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Specify dimensions\n",
    "\n",
    "while True:    \n",
    "    try:\n",
    "        dim = int(input(\"Please provide your desired grid dimension (dim X dim):\\n\"))\n",
    "        \n",
    "        if dim >= 5:\n",
    "            break\n",
    "            \n",
    "        print(\"Dimension needs to be larger than 4!\\n\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Please provide an integer value!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ic3vK2kG-fvk",
    "outputId": "c2ec3595-2d05-4a28-c070-6a83e3e70557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridworld:\n",
      "\n",
      "[['P' 'X' 'O' 'O' 'X']\n",
      " ['O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'X' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O']]\n",
      "\n",
      "\n",
      "Rewardworld:\n",
      "\n",
      "[['O' 'X' '-' 'O' 'X']\n",
      " ['O' 'O' 'O' '-' 'O']\n",
      " ['O' 'O' 'X' '-' 'O']\n",
      " ['-' '+' 'ยง' 'O' 'O']\n",
      " ['ยง' '-' 'O' 'O' 'O']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GW object\n",
    "\n",
    "gw = Gridworld(dim)\n",
    "\n",
    "gw.build()\n",
    "\n",
    "# Show GW\n",
    "#the state in the reward world with + is the terminal state\n",
    "\n",
    "gw.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gw.move(\"right\")\n",
    "# gw.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gw.reset()\n",
    "# gw.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57AJ24I9AdwW"
   },
   "source": [
    "n-step Sarsa, this code is taken from https://www.geeksforgeeks.org/sarsa-reinforcement-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4Bj7W5ocAdXK"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# set initial parameters\n",
    "epsilon = 0.9\n",
    "total_episodes = 90000000\n",
    "max_steps = 1000\n",
    "alpha = 0.8\n",
    "gamma = 0.9\n",
    "\n",
    "# define actionspace\n",
    "action_space=[0,1,2,3]\n",
    "dict_moves={0:\"left\",1:\"right\",2:\"up\",3:\"down\"}\n",
    "\n",
    "# list to save the SAR\n",
    "n_list=[]\n",
    " \n",
    "# initialize Q value table \n",
    "Q = np.zeros((dim*dim,len(action_space))) # dim: number of states x actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QLreRulLC0a2"
   },
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    \n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        \n",
    "        # sample random action\n",
    "        action = random.sample(action_space,1)[0] \n",
    "        return action\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # get best action (maximize Q value)\n",
    "        action = np.argmax(Q[state, :]) # requires index of the player (state)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FXv9Owq4C9hJ"
   },
   "outputs": [],
   "source": [
    "def update(state1,state2,reward,action1,action2):\n",
    "    \n",
    "#     print(\"current state (s): \",state1, \"\\n\", \"next state (s'): \",\n",
    "#           state2,\"\\n\",\"reward (r): \",reward,\"\\n\", \"current action (a): \",\n",
    "#           dict_moves[action1],\"\\n\", \"next action (a'): \",dict_moves[action2],\"\\n\")\n",
    "    \n",
    "    idx1 = np.where(state1 == \"P\")[0][0]\n",
    "    #print(\"index 1: \",idx1)\n",
    "    \n",
    "    idx2 = np.where(state2 ==\"P\")[0][0]\n",
    "    #print(\"index 2: \",idx2)\n",
    "    \n",
    "    # get estimates\n",
    "    Q_old = Q[idx1, action1]   \n",
    "    Q_new = Q[idx2, action2]\n",
    "    Q[idx1, action1] = Q_old + alpha * (reward + (gamma *  Q_new) - Q_old)\n",
    "    \n",
    "#     print(\"Q_old: \", Q_old)\n",
    "#     print(\"Q_new: \", Q_new)\n",
    "#     print((\"Reward: \", reward))\n",
    "#     print(\"Q_calc: \", (Q_old + alpha * (reward + (gamma *  Q_new) - Q_old)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9gWLz-5B-KN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100000\n",
      "Epoch: 200000\n",
      "Epoch: 300000\n",
      "Epoch: 400000\n",
      "Epoch: 500000\n",
      "Epoch: 600000\n",
      "Epoch: 700000\n",
      "Epoch: 800000\n",
      "Epoch: 900000\n",
      "Epoch: 1000000\n",
      "Epoch: 1100000\n",
      "Epoch: 1200000\n",
      "Epoch: 1300000\n",
      "Epoch: 1400000\n",
      "Epoch: 1500000\n",
      "Epoch: 1600000\n",
      "Epoch: 1700000\n",
      "Epoch: 1800000\n",
      "Epoch: 1900000\n",
      "Epoch: 2000000\n",
      "Epoch: 2100000\n",
      "Epoch: 2200000\n",
      "Epoch: 2300000\n",
      "Epoch: 2400000\n",
      "Epoch: 2500000\n",
      "Epoch: 2600000\n",
      "Epoch: 2700000\n",
      "Epoch: 2800000\n",
      "Epoch: 2900000\n",
      "Epoch: 3000000\n",
      "Epoch: 3100000\n",
      "Epoch: 3200000\n",
      "Epoch: 3300000\n",
      "Epoch: 3400000\n",
      "Epoch: 3500000\n",
      "Epoch: 3600000\n",
      "Epoch: 3700000\n",
      "Epoch: 3800000\n",
      "Epoch: 3900000\n",
      "Epoch: 4000000\n",
      "Epoch: 4100000\n",
      "Epoch: 4200000\n",
      "Epoch: 4300000\n",
      "Epoch: 4400000\n",
      "Epoch: 4500000\n",
      "Epoch: 4600000\n",
      "Epoch: 4700000\n",
      "Epoch: 4800000\n",
      "Epoch: 4900000\n",
      "Epoch: 5000000\n",
      "Epoch: 5100000\n",
      "Epoch: 5200000\n",
      "Epoch: 5300000\n",
      "Epoch: 5400000\n",
      "Epoch: 5500000\n",
      "Epoch: 5600000\n",
      "Epoch: 5700000\n",
      "Epoch: 5800000\n",
      "Epoch: 5900000\n",
      "Epoch: 6000000\n",
      "Epoch: 6100000\n",
      "Epoch: 6200000\n",
      "Epoch: 6300000\n",
      "Epoch: 6400000\n",
      "Epoch: 6500000\n",
      "Epoch: 6600000\n",
      "Epoch: 6700000\n",
      "Epoch: 6800000\n",
      "Epoch: 6900000\n",
      "Epoch: 7000000\n",
      "Epoch: 7100000\n",
      "Epoch: 7200000\n",
      "Epoch: 7300000\n",
      "Epoch: 7400000\n",
      "Epoch: 7500000\n",
      "Epoch: 7600000\n",
      "Epoch: 7700000\n",
      "Epoch: 7800000\n",
      "Epoch: 7900000\n",
      "Epoch: 8000000\n",
      "Epoch: 8100000\n",
      "Epoch: 8200000\n",
      "Epoch: 8300000\n",
      "Epoch: 8400000\n",
      "Epoch: 8500000\n",
      "Epoch: 8600000\n",
      "Epoch: 8700000\n",
      "Epoch: 8800000\n",
      "Epoch: 8900000\n",
      "Epoch: 9000000\n",
      "Epoch: 9100000\n",
      "Epoch: 9200000\n",
      "Epoch: 9300000\n",
      "Epoch: 9400000\n",
      "Epoch: 9500000\n",
      "Epoch: 9600000\n",
      "Epoch: 9700000\n",
      "Epoch: 9800000\n",
      "Epoch: 9900000\n",
      "Epoch: 10000000\n",
      "Epoch: 10100000\n",
      "Epoch: 10200000\n",
      "Epoch: 10300000\n",
      "Epoch: 10400000\n",
      "Epoch: 10500000\n",
      "Epoch: 10600000\n",
      "Epoch: 10700000\n",
      "Epoch: 10800000\n",
      "Epoch: 10900000\n",
      "Epoch: 11000000\n",
      "Epoch: 11100000\n",
      "Epoch: 11200000\n",
      "Epoch: 11300000\n",
      "Epoch: 11400000\n",
      "Epoch: 11500000\n",
      "Epoch: 11600000\n",
      "Epoch: 11700000\n",
      "Epoch: 11800000\n",
      "Epoch: 11900000\n",
      "Epoch: 12000000\n",
      "Epoch: 12100000\n",
      "Epoch: 12200000\n",
      "Epoch: 12300000\n",
      "Epoch: 12400000\n",
      "Epoch: 12500000\n",
      "Epoch: 12600000\n",
      "Epoch: 12700000\n",
      "Epoch: 12800000\n",
      "Epoch: 12900000\n",
      "Epoch: 13000000\n",
      "Epoch: 13100000\n",
      "Epoch: 13200000\n",
      "Epoch: 13300000\n",
      "Epoch: 13400000\n",
      "Epoch: 13500000\n",
      "Epoch: 13600000\n",
      "Epoch: 13700000\n",
      "Epoch: 13800000\n",
      "Epoch: 13900000\n",
      "Epoch: 14000000\n",
      "Epoch: 14100000\n",
      "Epoch: 14200000\n",
      "Epoch: 14300000\n",
      "Epoch: 14400000\n",
      "Epoch: 14500000\n",
      "Epoch: 14600000\n"
     ]
    }
   ],
   "source": [
    "# initializing the reward\n",
    "reward = 0\n",
    "\n",
    "# epoch_guide\n",
    "\n",
    "ep_ = 0\n",
    "\n",
    "# Starting the SARSA learning\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    \n",
    "    # every 100000 epochs\n",
    "    if (ep_ % 100000) == 0 and ep_ != 0:\n",
    "        print(\"Epoch: \" + str(ep_))\n",
    "        \n",
    "#         # check exploration status\n",
    "#         unique, counts = np.unique(Q, return_counts=True)\n",
    "#         tmp = dict(zip(unique, counts))\n",
    "#         if tmp[0] < ((dim*dim)/4): # if a less then a quarter of Q values is unexplored end the algorithm\n",
    "#             break\n",
    "#         else:\n",
    "#             print(\"Unexplored: \",(tmp[0]/Q.size)*100, \"%\")\n",
    "    \n",
    "    t = 0 # reset temperatur during episodes\n",
    "    stateTMP, _ = gw.reset() # reset gridworld and get initial state   \n",
    "    \n",
    "    state1 = copy.deepcopy(stateTMP) # prevent bugs \n",
    "    \n",
    "    idx_state1 = np.where(state1 == \"P\")[0][0] # state needs to be an index for the condition work \n",
    "    action1 = choose_action(idx_state1) # get current action\n",
    "\n",
    "    while t < max_steps: \n",
    "        \n",
    "        #sgw.visualize()\n",
    "         \n",
    "        # getting the next state\n",
    "        state2, done, reward = gw.move(dict_moves[action1])\n",
    "                \n",
    "        # get index of player in next state\n",
    "        idx_state2 = np.where(state2 == \"P\")[0][0]\n",
    "        \n",
    "        # choose the next action\n",
    "        action2 = choose_action(idx_state2) # state needs to be an index for the condition work\n",
    "         \n",
    "        # calculate the Q-value\n",
    "        update(state1, state2, reward, action1, action2)\n",
    "         \n",
    "        # update state and action\n",
    "        state1 = state2\n",
    "        action1 = action2\n",
    "        \n",
    "        # update temperature\n",
    "        t += 1\n",
    "         \n",
    "        #If at the end of learning process\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    ep_ += 1\n",
    "            \n",
    "print(\"Learning finished!\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNr6j-aLADOQ"
   },
   "outputs": [],
   "source": [
    "# Print final Q value table\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print learned policy for every state\n",
    "\n",
    "moves_ls = []\n",
    "dummy = np.array([0.,0.,0.,0.])\n",
    "\n",
    "for i in Q:\n",
    "    if (i==dummy).all(): # if state only has value of 0s\n",
    "        moves_ls.append(\"None\")\n",
    "        \n",
    "    else:\n",
    "        moves_ls.append(dict_moves[np.argmax(i)])\n",
    "    \n",
    "moves_ls = np.array(moves_ls)\n",
    "moves_ls = moves_ls.reshape(dim,dim)\n",
    "\n",
    "gw.reset() \n",
    "gw.visualize()\n",
    "\n",
    "print(\"Learned moves: \\n\")\n",
    "print(moves_ls)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Sarsa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
