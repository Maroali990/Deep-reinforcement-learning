{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E1jsBF16L8Zu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yRMb-GF7-L_V"
   },
   "outputs": [],
   "source": [
    "# Create Gridworld object\n",
    "\n",
    "class Gridworld:\n",
    "    \n",
    "    def __init__(self,dim):\n",
    "        \n",
    "        self.dim = dim\n",
    "        self.gid_world = []\n",
    "        self.reward_world = []\n",
    "        \n",
    "        self.gid_world_original = []\n",
    "        self.reward_world_original = []\n",
    "        \n",
    "        self.free_fields = []\n",
    "        self.goal = []\n",
    "        self.tele_idx = []\n",
    "        \n",
    "        self.finished = False\n",
    "        \n",
    "    \n",
    "    def build(self):\n",
    "        \n",
    "        ######### Build GW #########\n",
    "\n",
    "        for x in range(self.dim+1):\n",
    "            self.grid_world = [\"O\"] * (x * x)\n",
    "\n",
    "        # Create obstacles\n",
    "\n",
    "        self.grid_world = np.array(self.grid_world)\n",
    "\n",
    "        num_obs = int((self.dim*self.dim)/8) # specify number of obstacles\n",
    "\n",
    "        obstacle_indices = np.random.choice(np.arange(1,self.grid_world.size), replace=False, size=num_obs) # start at one to not place obstacles at player pos\n",
    "\n",
    "        self.grid_world[obstacle_indices] = \"X\"\n",
    "        \n",
    "        ######### Build RW and Teleport #########\n",
    "\n",
    "        # Assign rewards to states\n",
    "\n",
    "        self.reward_world =copy.deepcopy(self.grid_world.flatten()) # create seperate array for reward\n",
    "\n",
    "        self.free_fields = [x for x in np.arange(self.reward_world.size) if x not in obstacle_indices if x != 0] # generate list of free fields\n",
    "\n",
    "        np.random.shuffle(self.free_fields) # shuffle free fields\n",
    "\n",
    "        self.goal = self.free_fields[-1] # choose index for postive reward (terminal state)\n",
    "        \n",
    "        self.tele_idx = [self.free_fields[-2],self.free_fields[-3]]# choose 2 indices for teleports\n",
    "        \n",
    "        rew_neg_amount = 5 # specify number of negative rewards\n",
    "\n",
    "        rew_neg_indices = np.random.choice(self.free_fields[1:-3], replace=False, size=rew_neg_amount) # randomly choose incides for negative rewards\n",
    "\n",
    "        self.reward_world[rew_neg_indices] = \"-\" # place negative rewards\n",
    "\n",
    "        self.reward_world[self.goal] = \"+\" # place positive reward (terminal state)\n",
    "        \n",
    "        self.reward_world[self.tele_idx] = \"ยง\" # place teleports\n",
    "        \n",
    "        \n",
    "        # Set starting point #\n",
    "\n",
    "        self.grid_world[0] = \"P\" # top left\n",
    "        \n",
    "\n",
    "        # Save Backup\n",
    "\n",
    "        self.reward_world_original = copy.deepcopy(self.reward_world) \n",
    "        \n",
    "        self.grid_world_original = copy.deepcopy(self.grid_world)\n",
    "        \n",
    "        \n",
    "        return self.grid_world, self.reward_world\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.reward_world = self.reward_world_original\n",
    "        self.grid_world = self.grid_world_original\n",
    "\n",
    "        return self.grid_world, self.reward_world\n",
    "\n",
    "    def move(self, action):\n",
    "        \n",
    "        idx = np.where(self.grid_world == \"P\")[0]\n",
    "        idx = idx[0]\n",
    "        \n",
    "        self.reward = 0\n",
    "        \n",
    "        if action == \"left\":\n",
    "            \n",
    "            # if path is Oob\n",
    "            \n",
    "            if idx == 0 or (idx%self.dim) == 0:\n",
    "        \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx-1]  == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx-1 == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx-1 == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                   \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx-1] == \"+\":\n",
    "                        \n",
    "                        self.reward = +1\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx-1] == \"-\":\n",
    "                        \n",
    "                        self.reward = -1\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx-1] = \"P\"\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"right\":\n",
    "            \n",
    "            # if path is Oob\n",
    "            \n",
    "            if idx == (self.dim-1) or idx == (len(self.grid_world)-1):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx+1] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx+1 == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx+1 == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx+1] == \"+\":\n",
    "                        \n",
    "                        self.reward = +1\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx+1] == \"-\":\n",
    "                        \n",
    "                        self.reward = -1\n",
    "                        \n",
    "                    # move player\n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx+1] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"up\":\n",
    "            \n",
    "             # if path is Oob\n",
    "            \n",
    "            if idx in range(0,(self.dim-1)):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx-self.dim] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx-self.dim == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx-self.dim == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx-self.dim] == \"+\":\n",
    "                        \n",
    "                        self.reward = +1\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx-self.dim] == \"-\":\n",
    "                        \n",
    "                        self.reward = -1\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx-self.dim] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        elif action == \"down\":\n",
    "            \n",
    "             # if path is Oob\n",
    "            \n",
    "            if idx in range(len(self.grid_world)-self.dim,len(self.grid_world)):\n",
    "                \n",
    "                return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.grid_world[idx+self.dim] == \"X\":\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # check for teleports and teleport with 60% probability\n",
    "                \n",
    "                elif idx+self.dim == self.tele_idx[0] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[1]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                    \n",
    "                elif idx+self.dim == self.tele_idx[1] and random.randint(0,100) > 40:\n",
    "                    \n",
    "                    # teleport player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[self.tele_idx[0]] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "                \n",
    "                # if path isnt blocked\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    # check for rewards\n",
    "                    \n",
    "                    if self.reward_world[idx+self.dim] == \"+\":\n",
    "                        \n",
    "                        self.reward = +1\n",
    "                        self.finished = True\n",
    "                        \n",
    "                    elif self.reward_world[idx+self.dim] == \"-\":\n",
    "                        \n",
    "                        self.reward = -1\n",
    "                        \n",
    "                    # move player\n",
    "                    \n",
    "                    self.grid_world[idx] = \"O\"\n",
    "                    \n",
    "                    self.grid_world[idx+self.dim] = \"P\"\n",
    "                    \n",
    "                    return self.grid_world, self.finished, self.reward\n",
    "            \n",
    "        else:\n",
    "            print(\"Please choose an action [left,right,up,down]!\")        \n",
    "    \n",
    "    def visualize(self):\n",
    "        \n",
    "        # Show GW\n",
    "        \n",
    "        print(\"Gridworld:\\n\")\n",
    "        print(self.grid_world.reshape(((self.dim, self.dim))))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Show RW\n",
    "\n",
    "        print(\"Rewardworld:\\n\")\n",
    "        print(self.reward_world.reshape(((self.dim, self.dim))))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhdb6GBm-ZR0",
    "outputId": "bff39063-2885-44a9-f5d6-7502ecdbf6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your desired grid dimension (dim X dim):\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Specify dimensions\n",
    "\n",
    "while True:    \n",
    "    try:\n",
    "        dim = int(input(\"Please provide your desired grid dimension (dim X dim):\\n\"))\n",
    "        \n",
    "        if dim >= 5:\n",
    "            break\n",
    "            \n",
    "        print(\"Dimension needs to be larger than 4!\\n\")\n",
    "    \n",
    "    except:\n",
    "        print(\"Please provide an integer value!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ic3vK2kG-fvk",
    "outputId": "c2ec3595-2d05-4a28-c070-6a83e3e70557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridworld:\n",
      "\n",
      "[['P' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'X' 'X' 'O' 'O' 'O' 'X']\n",
      " ['X' 'X' 'O' 'O' 'O' 'O' 'X' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'X' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'X' 'O' 'O' 'O' 'O' 'O' 'O']]\n",
      "\n",
      "\n",
      "Rewardworld:\n",
      "\n",
      "[['O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'O' 'ยง' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' 'X' 'X' 'O' 'O' 'O' 'X']\n",
      " ['X' 'X' 'O' 'O' '-' 'O' 'X' '-']\n",
      " ['O' 'O' 'O' 'O' 'O' 'O' '+' 'O']\n",
      " ['O' 'O' 'X' 'O' 'O' 'O' 'O' 'O']\n",
      " ['O' 'O' '-' 'O' '-' 'O' 'ยง' 'O']\n",
      " ['O' 'X' 'O' 'O' 'O' 'O' 'O' '-']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create GW object\n",
    "\n",
    "gw = Gridworld(dim)\n",
    "\n",
    "gw.build()\n",
    "\n",
    "# Show GW\n",
    "#the state in the reward world with + is the terminal state\n",
    "\n",
    "gw.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57AJ24I9AdwW"
   },
   "source": [
    "n-step Sarsa, this code is taken from https://www.geeksforgeeks.org/sarsa-reinforcement-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4Bj7W5ocAdXK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4)\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "# set initial parameters\n",
    "epsilon = 0.9\n",
    "total_episodes = 5000000\n",
    "max_steps = 30\n",
    "alpha = 0.8\n",
    "gamma = 0.9\n",
    "\n",
    "# define actionspace\n",
    "action_space=[0,1,2,3]\n",
    "dict_moves={0:\"left\",1:\"right\",2:\"up\",3:\"down\"}\n",
    "\n",
    "# list to save the SAR\n",
    "n_list=[]\n",
    " \n",
    "# initialize Q value table \n",
    "Q = np.zeros((dim*dim,len(action_space))) # dim: number of states x actions\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QLreRulLC0a2"
   },
   "outputs": [],
   "source": [
    "def choose_action(state):\n",
    "    \n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        \n",
    "        # sample random action\n",
    "        action = random.sample(action_space,1)[0] \n",
    "        \n",
    "        return action\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # get best action (maximize Q value)\n",
    "        action = np.argmax(Q[state, :]) # requires index of the player (state)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FXv9Owq4C9hJ"
   },
   "outputs": [],
   "source": [
    "def update(state1,state2,reward,action1,action2):\n",
    "    \n",
    "#     print(\"current state (s): \",state1, \"\\n\", \"next state (s'): \",\n",
    "#           state2,\"\\n\",\"reward (r): \",reward,\"\\n\", \"current action (a): \",\n",
    "#           dict_moves[action1],\"\\n\", \"next action (a'): \",dict_moves[action2],\"\\n\")\n",
    "    \n",
    "    idx1 = np.where(state1 == \"P\")[0][0]\n",
    "    #print(\"index 1: \",idx1)\n",
    "    \n",
    "    idx2 = np.where(state2 ==\"P\")[0][0]\n",
    "    #print(\"index 2: \",idx2)\n",
    "    \n",
    "    # get estimates\n",
    "    Q_old = Q[idx1, action1]\n",
    "    Q_new = reward + gamma * Q[idx2, action2]\n",
    "    Q[idx1, action1] = Q_old + alpha * (Q_new - Q_old) \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "U9gWLz-5B-KN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 200000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 300000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 400000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 500000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 600000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 700000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 800000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 900000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1000000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1100000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1200000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1300000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1400000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1500000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1600000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1700000\n",
      "Unexplored:  92.578125 %\n",
      "Epoch: 1800000\n",
      "Unexplored:  92.578125 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/2686666849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# choose the next action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0maction2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx_state2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# state needs to be an index for the condition work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# calculate the Q-value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3100/618635211.py\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# get best action (maximize Q value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# requires index of the player (state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \"\"\"\n\u001b[1;32m-> 1195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initializing the reward\n",
    "reward=0\n",
    "\n",
    "# epoch_guide\n",
    "\n",
    "ep_ = 1\n",
    "\n",
    "# Starting the SARSA learning\n",
    "\n",
    "for episode in range(total_episodes):\n",
    "    \n",
    "    # every 100000 steps\n",
    "    if (ep_ % 100000) == 0:\n",
    "        print(\"Epoch: \" + str(ep_))\n",
    "        \n",
    "        # check exploration status\n",
    "        unique, counts = np.unique(Q, return_counts=True)\n",
    "        tmp = dict(zip(unique, counts))\n",
    "        if tmp[0.0] < ((dim*dim)/4): # if a less then a quarter of Q values is unexplored end the algorithm\n",
    "            break\n",
    "        else:\n",
    "            print(\"Unexplored: \",(tmp[0.0]/Q.size)*100, \"%\")\n",
    "    \n",
    "    t = 0 # reset temperatur during episodes\n",
    "    state1, _ = gw.reset() # reset gridworld and get initial state     \n",
    "    \n",
    "    idx_state1 = np.where(state1 == \"P\")[0][0] # state needs to be an index for the condition work\n",
    "    \n",
    "    action1 = choose_action(idx_state1) # get current action\n",
    "\n",
    "    while t < max_steps: \n",
    "         \n",
    "        # getting the next state\n",
    "        state2, done, reward = gw.move(dict_moves[action1])\n",
    "        \n",
    "        # get index of player in next state\n",
    "        idx_state2 = np.where(state2 == \"P\")[0][0]\n",
    "        \n",
    "        # choose the next action\n",
    "        action2 = choose_action(idx_state2) # state needs to be an index for the condition work\n",
    "         \n",
    "        # calculate the Q-value\n",
    "        update(state1, state2, reward, action1, action2)\n",
    "         \n",
    "        # update state and action\n",
    "        state1 = state2\n",
    "        action1 = action2\n",
    "         \n",
    "        #Updating the respective vaLues\n",
    "        t += 1\n",
    "        reward += reward\n",
    "         \n",
    "        #If at the end of learning process\n",
    "        if done:\n",
    "            ep_ += 1\n",
    "            break\n",
    "            \n",
    "print(\"Learning finished!\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yNr6j-aLADOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01 -1.00000000e+01 -1.00000000e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.80048302e-08  0.00000000e+00 -1.71420899e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.17831785e+00  4.23537337e+00  3.03656237e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.11933250e+00 -2.62239624e+00 -2.73557079e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e+01 -1.00000000e+01 -1.00000000e+01 -1.00000000e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.90332272e+00 -1.04593856e+00 -8.33464292e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Print final Q value table\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " Sarsa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
